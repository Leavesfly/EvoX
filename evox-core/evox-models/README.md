# EvoX Models â€” LLM æ¨¡å‹é€‚é…æ¨¡å—

## ğŸ“¦ æ¨¡å—å®šä½

**å±‚çº§**: æ ¸å¿ƒå±‚ (Core Layer)  
**èŒè´£**: æä¾›ç»Ÿä¸€çš„ LLM æ¨¡å‹é€‚é…å±‚ï¼Œæ”¯æŒå¤šç§å¤§æ¨¡å‹æä¾›å•†  
**ä¾èµ–**: evox-core  
**æ¶æ„**: Clean Architectureï¼ˆSPI â†’ Protocol â†’ Support â†’ Provider â†’ Configï¼‰

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

evox-models ä¸º EvoX æ¡†æ¶æä¾›ç»Ÿä¸€çš„å¤§è¯­è¨€æ¨¡å‹ (LLM) æŠ½è±¡æ¥å£å’Œå¤šç§æ¨¡å‹æä¾›å•†çš„é€‚é…å®ç°ï¼Œå±è”½ä¸åŒæ¨¡å‹ API çš„å·®å¼‚ï¼Œè®©ä¸Šå±‚ä¸šåŠ¡æ— éœ€å…³å¿ƒå…·ä½“æ¨¡å‹å®ç°ã€‚

### æ”¯æŒçš„æ¨¡å‹æä¾›å•†

| æä¾›å•† | å®ç°ç±» | é»˜è®¤æ¨¡å‹ | åè®® | Tool Use |
|--------|--------|---------|------|----------|
| **OpenAI** | `OpenAILLM` | `gpt-4o-mini` | OpenAI å…¼å®¹ | âœ… |
| **é˜¿é‡Œäº‘é€šä¹‰** | `AliyunLLM` | `qwen-turbo` | OpenAI å…¼å®¹ | âœ… |
| **DeepSeek** | `DeepSeekLLM` | `deepseek-chat` | OpenAI å…¼å®¹ | âœ… |
| **Anthropic** | `AnthropicLLM` | `claude-3-5-sonnet` | è‡ªå®šä¹‰ | âœ… |
| **Gemini** | `GeminiLLM` | `gemini-pro` | è‡ªå®šä¹‰ | âœ… |
| **OpenRouter** | `OpenRouterLLM` | å¯é€‰ | OpenAI å…¼å®¹ | âœ… |
| **ç¡…åŸºæµåŠ¨** | `SiliconFlowLLM` | å¯é€‰ | OpenAI å…¼å®¹ | âŒ |
| **Ollama** | `OllamaLLM` | `llama2` | OpenAI å…¼å®¹ | âŒ |

## ğŸ“‚ åŒ…ç»“æ„ (Clean Architecture)

```
io.leavesfly.evox.models/
â”‚
â”œâ”€â”€ spi/                        # æœåŠ¡æä¾›è€…æ¥å£å±‚ (æœ€å†…å±‚)
â”‚   â”œâ”€â”€ LLMProvider.java        #   æ ¸å¿ƒ SPI æ¥å£ï¼Œç»§æ‰¿ ILLM + ILLMToolUse
â”‚   â””â”€â”€ LLMException.java       #   ç»Ÿä¸€å¼‚å¸¸å®šä¹‰
â”‚
â”œâ”€â”€ protocol/                   # åè®®å±‚ â€” OpenAI å…¼å®¹ HTTP åè®®
â”‚   â”œâ”€â”€ OpenAiCompatibleClient.java
â”‚   â”œâ”€â”€ ChatCompletionRequest.java
â”‚   â”œâ”€â”€ ChatCompletionResponse.java
â”‚   â”œâ”€â”€ ChatCompletionResult.java
â”‚   â”œâ”€â”€ ToolCall.java
â”‚   â”œâ”€â”€ ToolDefinition.java
â”‚   â”œâ”€â”€ EmbeddingRequest.java
â”‚   â”œâ”€â”€ EmbeddingResponse.java
â”‚   â”œâ”€â”€ ImageGenerationRequest.java
â”‚   â””â”€â”€ ImageGenerationResponse.java
â”‚
â”œâ”€â”€ support/                    # æ”¯æ’‘å±‚ â€” å…¬å…±åŸºç±»
â”‚   â””â”€â”€ OpenAiCompatibleLLM.java  # æ‰€æœ‰ OpenAI å…¼å®¹ provider çš„æŠ½è±¡åŸºç±»
â”‚
â”œâ”€â”€ provider/                   # Provider å®ç°å±‚ (æ¯ä¸ª provider å†…èš)
â”‚   â”œâ”€â”€ openai/
â”‚   â”‚   â”œâ”€â”€ OpenAILLMConfig.java
â”‚   â”‚   â””â”€â”€ OpenAILLM.java
â”‚   â”œâ”€â”€ deepseek/
â”‚   â”‚   â”œâ”€â”€ DeepSeekLLMConfig.java
â”‚   â”‚   â””â”€â”€ DeepSeekLLM.java
â”‚   â”œâ”€â”€ aliyun/
â”‚   â”‚   â”œâ”€â”€ AliyunLLMConfig.java
â”‚   â”‚   â””â”€â”€ AliyunLLM.java
â”‚   â”œâ”€â”€ ollama/
â”‚   â”‚   â”œâ”€â”€ OllamaLLMConfig.java
â”‚   â”‚   â””â”€â”€ OllamaLLM.java
â”‚   â”œâ”€â”€ anthropic/
â”‚   â”‚   â”œâ”€â”€ AnthropicLLMConfig.java
â”‚   â”‚   â””â”€â”€ AnthropicLLM.java
â”‚   â”œâ”€â”€ gemini/
â”‚   â”‚   â”œâ”€â”€ GeminiLLMConfig.java
â”‚   â”‚   â””â”€â”€ GeminiLLM.java
â”‚   â”œâ”€â”€ openrouter/
â”‚   â”‚   â”œâ”€â”€ OpenRouterLLMConfig.java
â”‚   â”‚   â””â”€â”€ OpenRouterLLM.java
â”‚   â””â”€â”€ siliconflow/
â”‚       â”œâ”€â”€ SiliconFlowLLMConfig.java
â”‚       â””â”€â”€ SiliconFlowLLM.java
â”‚
â””â”€â”€ config/                     # é…ç½®é—¨é¢å±‚ (æœ€å¤–å±‚)
    â”œâ”€â”€ LLMConfigs.java         #   é…ç½®å¿«æ·åˆ›å»ºå·¥å…·
    â””â”€â”€ LLMFactory.java         #   LLM å·¥å‚ï¼Œæ ¹æ®é…ç½®è‡ªåŠ¨åˆ›å»ºå®ä¾‹
```

### æ¶æ„åˆ†å±‚è¯´æ˜

| å±‚ | èŒè´£ | ä¾èµ–æ–¹å‘ |
|----|------|----------|
| **spi** | å®šä¹‰æ ¸å¿ƒæ¥å£å’Œå¼‚å¸¸ï¼Œä¸ä¾èµ–ä»»ä½•å®ç° | æ— å¤–éƒ¨ä¾èµ– |
| **protocol** | å°è£… OpenAI å…¼å®¹ HTTP åè®®ç»†èŠ‚ | â†’ spi |
| **support** | æå–å…¬å…±é€»è¾‘ä¸ºæŠ½è±¡åŸºç±»ï¼Œæ¶ˆé™¤é‡å¤ä»£ç  | â†’ spi, protocol |
| **provider** | å„ provider çš„å®ç°ç±»å’Œé…ç½®ç±»å†…èšåœ¨ä¸€èµ· | â†’ spi, protocol, support |
| **config** | å¯¹å¤–æš´éœ²çš„é…ç½®é—¨é¢å’Œå·¥å‚ | â†’ provider |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### Maven ä¾èµ–

```xml
<dependency>
    <groupId>io.leavesfly.evox</groupId>
    <artifactId>evox-models</artifactId>
    <version>1.0.0-SNAPSHOT</version>
</dependency>
```

### æ–¹å¼ä¸€ï¼šä½¿ç”¨ LLMFactory å¿«æ·åˆ›å»º

```java
import io.leavesfly.evox.models.config.LLMFactory;
import io.leavesfly.evox.models.spi.LLMProvider;

// OpenAI
LLMProvider llm = LLMFactory.openai("sk-xxx", "gpt-4o");

// é˜¿é‡Œäº‘é€šä¹‰åƒé—®
LLMProvider llm = LLMFactory.aliyun("sk-xxx", "qwen-max");

// DeepSeek
LLMProvider llm = LLMFactory.deepseek("sk-xxx");

// Ollama æœ¬åœ°æ¨¡å‹
LLMProvider llm = LLMFactory.ollama("llama3");

// ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼ˆè‡ªåŠ¨è¯»å– OPENAI_API_KEY ç­‰ï¼‰
LLMProvider llm = LLMFactory.openai();
```

### æ–¹å¼äºŒï¼šä½¿ç”¨ LLMConfigs åˆ›å»ºé…ç½®

```java
import io.leavesfly.evox.models.config.LLMConfigs;
import io.leavesfly.evox.models.config.LLMFactory;

var config = LLMConfigs.openAI("sk-xxx", "gpt-4o-mini");
LLMProvider llm = LLMFactory.create(config);

String response = llm.generate("è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½");
```

### æ–¹å¼ä¸‰ï¼šç›´æ¥ä½¿ç”¨ Provider

```java
import io.leavesfly.evox.models.provider.openai.*;

OpenAILLMConfig config = OpenAILLMConfig.builder()
    .apiKey("sk-xxx")
    .model("gpt-4o-mini")
    .temperature(0.7f)
    .maxTokens(2000)
    .build();

OpenAILLM llm = new OpenAILLM(config);
String response = llm.generate("è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½");
```

### ç¯å¢ƒå˜é‡é…ç½®

```bash
# OpenAI
OPENAI_API_KEY=sk-your-api-key

# é˜¿é‡Œäº‘é€šä¹‰
DASHSCOPE_API_KEY=your-dashscope-key

# DeepSeek
DEEPSEEK_API_KEY=your-deepseek-key

# ç¡…åŸºæµåŠ¨
SILICONFLOW_API_KEY=your-siliconflow-key
```

## ğŸ’¡ é«˜çº§ç”¨æ³•

### æ¶ˆæ¯å†å²å¯¹è¯

```java
List<Message> messages = List.of(
    Message.builder()
        .content("ä½ æ˜¯ä¸€ä¸ªPythonä¸“å®¶")
        .messageType(MessageType.SYSTEM)
        .build(),
    Message.builder()
        .content("å¦‚ä½•å®ç°å¿«é€Ÿæ’åº?")
        .messageType(MessageType.INPUT)
        .build()
);

String response = llm.generate(messages);
```

### æµå¼è¾“å‡º

```java
Flux<String> stream = llm.stream("è®²ä¸€ä¸ªæœ‰è¶£çš„æ•…äº‹");
stream.subscribe(
    chunk -> System.out.print(chunk),
    error -> log.error("Error", error),
    () -> System.out.println("\nå®Œæˆ")
);
```

### Tool Use / Function Calling

```java
import io.leavesfly.evox.models.protocol.ToolDefinition;

List<ToolDefinition> tools = List.of(
    ToolDefinition.builder()
        .name("get_weather")
        .description("è·å–å¤©æ°”ä¿¡æ¯")
        .parameters(paramSchema)
        .build()
);

ChatCompletionResult result = llm.chatWithTools(messages, tools);
```

### æ‰©å±•è‡ªå®šä¹‰ Provider

ç»§æ‰¿ `OpenAiCompatibleLLM` å³å¯å¿«é€Ÿæ¥å…¥ä»»ä½• OpenAI å…¼å®¹çš„ APIï¼š

```java
public class MyCustomLLM extends OpenAiCompatibleLLM {
    public MyCustomLLM(MyCustomConfig config) {
        super(config, "https://my-api.example.com/v1");
    }
}
```

## ğŸ“ è®¾è®¡åŸåˆ™

- **Clean Architecture**: ä¸¥æ ¼åˆ†å±‚ï¼Œä¾èµ–æ–¹å‘ç”±å¤–å‘å†…
- **Provider å†…èš**: æ¯ä¸ª provider çš„å®ç°ç±»å’Œé…ç½®ç±»æ”¾åœ¨åŒä¸€ä¸ªåŒ…ä¸‹
- **æ¶ˆé™¤é‡å¤**: OpenAI å…¼å®¹ provider å…±äº« `OpenAiCompatibleLLM` åŸºç±»
- **SPI è§£è€¦**: ä¸Šå±‚æ¨¡å—åªä¾èµ– `LLMProvider` æ¥å£ï¼Œä¸æ„ŸçŸ¥å…·ä½“å®ç°
- **å“åº”å¼ç¼–ç¨‹**: åŸºäº Reactorï¼Œæ”¯æŒåŒæ­¥ã€å¼‚æ­¥å’Œæµå¼è°ƒç”¨

## ğŸ”— ç›¸å…³æ¨¡å—

- **evox-core**: æä¾›åŸºç¡€æŠ½è±¡å’Œæ¶ˆæ¯ç³»ç»Ÿ
- **evox-actions**: ä½¿ç”¨ LLM æ‰§è¡Œå„ç§åŠ¨ä½œ
- **evox-agents**: Agent ä½¿ç”¨ LLM è¿›è¡Œæ¨ç†å’Œå†³ç­–
- **evox-optimizers**: ä¼˜åŒ– Prompt å’Œæ¨¡å‹å‚æ•°

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **API å¯†é’¥å®‰å…¨**: ä¸è¦å°† API å¯†é’¥ç¡¬ç¼–ç ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡
2. **æˆæœ¬æ§åˆ¶**: è®¾ç½®åˆç†çš„ `maxTokens`ï¼Œé¿å…è¿‡åº¦æ¶ˆè€—
3. **è¶…æ—¶è®¾ç½®**: æ ¹æ®ä¸šåŠ¡åœºæ™¯è®¾ç½®åˆç†çš„ `timeout`
4. **é”™è¯¯å¤„ç†**: æ•è·å¹¶å¤„ç† `LLMException`
5. **é€Ÿç‡é™åˆ¶**: æ³¨æ„å„æä¾›å•†çš„ API é€Ÿç‡é™åˆ¶
