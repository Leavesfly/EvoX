package io.leavesfly.evox.claudecode.agent;

import io.leavesfly.evox.core.message.Message;
import io.leavesfly.evox.memory.manager.MemoryManager;
import io.leavesfly.evox.models.spi.LLMProvider;
import lombok.extern.slf4j.Slf4j;

import java.util.List;
import java.util.function.Consumer;

/**
 * å¯¹è¯å†å²å‹ç¼©å™¨
 * è´Ÿè´£ä¼°ç®— token æ•°é‡ã€åˆ¤æ–­æ˜¯å¦éœ€è¦å‹ç¼©ã€ä½¿ç”¨ LLM ç”Ÿæˆæ‘˜è¦å¹¶æ›¿æ¢å†å²ã€‚
 */
@Slf4j
public class HistoryCompactor {

    private static final int COMPACT_THRESHOLD = 6;

    private final MemoryManager memoryManager;
    private final LLMProvider llm;
    private final int contextWindow;
    private final Consumer<String> streamEmitter;

    public HistoryCompactor(MemoryManager memoryManager, LLMProvider llm,
                            int contextWindow, Consumer<String> streamEmitter) {
        this.memoryManager = memoryManager;
        this.llm = llm;
        this.contextWindow = contextWindow;
        this.streamEmitter = streamEmitter;
    }

    /**
     * ä¼°ç®—æ¶ˆæ¯åˆ—è¡¨çš„ token æ•°é‡ï¼ˆç²—ç•¥ä¼°ç®—ï¼šæ¯ 4 ä¸ªå­—ç¬¦çº¦ 1 ä¸ª tokenï¼‰
     */
    public int estimateTokenCount(List<Message> messages) {
        int totalChars = 0;
        for (Message message : messages) {
            if (message.getContent() != null) {
                totalChars += message.getContent().toString().length();
            }
        }
        return totalChars / 4;
    }

    /**
     * æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨å‹ç¼©ï¼Œå¦‚æœéœ€è¦åˆ™æ‰§è¡Œå‹ç¼©
     */
    public void autoCompactIfNeeded(List<Message> conversationMessages) {
        int estimatedTokens = estimateTokenCount(conversationMessages);
        if (estimatedTokens > contextWindow * 0.8) {
            emitStream("\nğŸ“¦ Compacting conversation history to free up tokens...\n");
            compact();
        }
    }

    /**
     * å‹ç¼©å¯¹è¯å†å²ï¼šä½¿ç”¨ LLM ç”Ÿæˆæ‘˜è¦ï¼Œæ›¿æ¢åŸå§‹å†å²
     */
    public void compact() {
        List<Message> allMessages = memoryManager.getAllMessages();
        if (allMessages.size() < COMPACT_THRESHOLD) {
            emitStream("â„¹ï¸ Not enough messages to compact (need at least " + COMPACT_THRESHOLD + ").\n");
            return;
        }

        emitStream("ğŸ“¦ Compacting " + allMessages.size() + " messages...\n");

        String summary = generateSummary(allMessages);

        memoryManager.clearAll();
        memoryManager.addMessage(Message.systemMessage(
                "[Conversation Summary]\n" + summary
                        + "\n\n[Note: Previous conversation was compacted. "
                        + "The above is a summary of what was discussed and accomplished.]"));

        emitStream("âœ… Compacted to summary (" + summary.length() + " chars)\n");
    }

    /**
     * ä½¿ç”¨ LLM ç”Ÿæˆå¯¹è¯æ‘˜è¦
     */
    private String generateSummary(List<Message> messages) {
        StringBuilder conversationText = new StringBuilder();
        for (Message message : messages) {
            String role = message.getMessageType() != null ? message.getMessageType().name() : "UNKNOWN";
            String content = message.getContent() != null ? message.getContent().toString() : "";
            if (content.length() > 500) {
                content = content.substring(0, 500) + "... (truncated)";
            }
            conversationText.append(role).append(": ").append(content).append("\n");
        }

        String summaryPrompt = """
                Summarize the following conversation between a user and a coding assistant.
                Focus on:
                1. What the user asked for (their goals and requirements)
                2. What was accomplished (files created, modified, commands run)
                3. What tools were used and their key results
                4. Any important decisions or context established
                5. Any errors encountered and how they were resolved
                
                Be concise but preserve all actionable information. Use bullet points.
                
                Conversation:
                """ + conversationText;

        try {
            return llm.generate(summaryPrompt);
        } catch (Exception e) {
            log.warn("Failed to generate LLM summary, falling back to simple marker", e);
            return "[Summary generation failed. " + messages.size()
                    + " messages were removed to reduce context length.]";
        }
    }

    private void emitStream(String text) {
        if (streamEmitter != null) {
            streamEmitter.accept(text);
        }
    }
}
